{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入各种包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  #1.5.1+cuda9.2\n",
    "from torchvision import datasets,transforms  #torchvision 0.6.1 +cuda9.2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "import os,time\n",
    "device = torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建generate网络（生成器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generate,self).__init__()\n",
    "        self.fc1=nn.Linear(100,256)\n",
    "        self.bn1=nn.BatchNorm1d(256)\n",
    "        self.lfc1=nn.Linear(10,256)\n",
    "        self.lbn1=nn.BatchNorm1d(256)\n",
    "        self.fc2=nn.Linear(512,512)\n",
    "        self.bn2=nn.BatchNorm1d(512)\n",
    "        self.fc3=nn.Linear(512,1024)\n",
    "        self.bn3=nn.BatchNorm1d(1024)\n",
    "        self.fc4=nn.Linear(1024,784)\n",
    "    def forward(self,input,label):\n",
    "        x=F.relu(self.bn1(self.fc1(input)))    #改成leaky_relu效果更好，可以试着一下\n",
    "        y=F.relu(self.lbn1(self.lfc1(label)))\n",
    "        x=torch.cat([x,y],1)\n",
    "        x=F.relu(self.bn2(self.fc2(x)))\n",
    "        x=F.relu(self.bn3(self.fc3(x)))\n",
    "        x=torch.tanh(self.fc4(x))\n",
    "        return x\n",
    "    #对线性层的参数进行初始化\n",
    "    def weight_init(self,mean,std):\n",
    "        for i in self._modules:\n",
    "            if isinstance(i,nn.Linear):\n",
    "                i.weight.data.normal_(mean,std)\n",
    "                i.bias.data.zero_()#后面带下划线表示就在原先的i上更改\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=generate() #创建生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.to(device)#如果有GPU，把G放到GPU上运行，没有就放到CPU上运行\n",
    "G.weight_init(0,0.02)#初始化权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建discriminator网络（判别器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator,self).__init__()\n",
    "        self.fc1 = nn.Linear(784,1024)\n",
    "        self.lfc1=nn.Linear(10,1024)\n",
    "        self.fc2=nn.Linear(2048,512)\n",
    "        self.bn2=nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4=nn.Linear(512,1)\n",
    "    def forward(self,input,label):\n",
    "        x=F.leaky_relu(self.fc1(input),0.2)\n",
    "        y=F.leaky_relu(self.lfc1(label),0.2)\n",
    "        x=torch.cat([x,y],1)\n",
    "        x=F.leaky_relu(self.bn2(self.fc2(x)),0.2)\n",
    "        #x=F.leaky_relu(self.bn3(self.fc3(x)),0.2)\n",
    "        x=torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "    def weight_init(self,mean,std):\n",
    "        for i in self._modules:\n",
    "            if isinstance(i,nn.Linear):\n",
    "                i.weight.data.normal_(mean,std)\n",
    "                i.bias.data.zero_()#后面带下划线表示就在原先的i上更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=discriminator() #创建判别器\n",
    "D.to(device)   #依情况放到CPU或者GPU上\n",
    "D.weight_init(0,0.2) #对其参数进行初始化\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对抗训练过程准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(), #把一个PIL图像或者numpy数组转换为tensor进行下面的数据增强操作\n",
    "    transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "])\n",
    "train_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',train=True,download=True,transform=transform),batch_size=batch_size,shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制造一些带标签的假数据，用来输入到训练好的generate中看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=torch.rand(100,100)\n",
    "tmp_noise_label=torch.zeros(10,1)\n",
    "for i in range(9):\n",
    "    temp=torch.ones(10,1)+i\n",
    "    tmp_noise_label=torch.cat([tmp_noise_label,temp],0)   #(100,10)\n",
    "noise_label=torch.zeros(100,10)\n",
    "noise_label.scatter_(1,tmp_noise_label.type(torch.LongTensor),1)\n",
    "noise=noise.to(device)\n",
    "noise_label=noise_label.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个函数，用来将假数据通过generate生成的图片保存起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(path=\"./result.jpg\"):\n",
    "    G.eval()#将生成器调成eval模式\n",
    "    generated=G(noise,noise_label)#将之前的假数据输入生成fake图像\n",
    "    G.train()#将生成器模式复原\n",
    "    a=generated.view(generated.size(0),1,28,28)\n",
    "    print(a.size())\n",
    "    save_image(a,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置训练参数，给网络选择合适的优化器，选择合适的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f0f054226d0>\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "lr=0.0002\n",
    "train_epoch=20\n",
    "print(G.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "optiG=optim.Adam(G.parameters(),lr=lr,betas=(0.5,0.999))#给G选择Adam作为优化器\n",
    "optiD=optim.Adam(D.parameters(),lr=lr,betas=(0.5,0.999))#给D选择Adam作为优化器\n",
    "loss=nn.BCELoss() #选择二分类交叉熵损失作为损失函数，因为最后的损失都是判别器的效果来看的。即分的准不准确\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成一些文件夹用来保存实验结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"result\"):\n",
    "    os.mkdir(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002\n"
     ]
    }
   ],
   "source": [
    "print(optiG.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练！\n",
      "第0个epoch： G的损失:0.88, D的损失:1.22\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：27.73 s\n",
      "第1个epoch： G的损失:0.89, D的损失:1.23\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.39 s\n",
      "第2个epoch： G的损失:0.86, D的损失:1.22\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.33 s\n",
      "第3个epoch： G的损失:0.87, D的损失:1.22\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.72 s\n",
      "第4个epoch： G的损失:0.87, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：26.23 s\n",
      "第5个epoch： G的损失:0.87, D的损失:1.25\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：21.86 s\n",
      "第6个epoch： G的损失:0.87, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：26.81 s\n",
      "第7个epoch： G的损失:0.86, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：29.11 s\n",
      "第8个epoch： G的损失:0.88, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.85 s\n",
      "第9个epoch： G的损失:0.86, D的损失:1.23\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：29.37 s\n",
      "第10个epoch： G的损失:0.87, D的损失:1.25\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：27.60 s\n",
      "第11个epoch： G的损失:0.88, D的损失:1.25\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.64 s\n",
      "第12个epoch： G的损失:0.88, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：29.33 s\n",
      "第13个epoch： G的损失:0.86, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：23.19 s\n",
      "第14个epoch： G的损失:0.87, D的损失:1.23\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：25.87 s\n",
      "第15个epoch： G的损失:0.89, D的损失:1.23\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：29.57 s\n",
      "第16个epoch： G的损失:0.89, D的损失:1.23\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：29.21 s\n",
      "第17个epoch： G的损失:0.90, D的损失:1.24\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.71 s\n",
      "第18个epoch： G的损失:0.88, D的损失:1.21\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.26 s\n",
      "第19个epoch： G的损失:0.92, D的损失:1.21\n",
      "torch.Size([100, 1, 28, 28])\n",
      "此epoch耗时为：28.02 s\n",
      "训练总耗时为：553.81 s\n"
     ]
    }
   ],
   "source": [
    "print(\"开始训练！\")\n",
    "start_time=time.time()\n",
    "for epoch in range(train_epoch):\n",
    "    D_losses=[]\n",
    "    G_losses=[]\n",
    "    epoch_start_time=time.time()\n",
    "    #前期让学习率大一些，训练到一定epoch，减小lr，再更加精细的训练，可以提高训练速度\n",
    "    if epoch==30:\n",
    "        optiG.param_groups[0]['lr']/=10\n",
    "        optiD.param_groups[0]['lr']/=10\n",
    "        print(\"将学习率降至：\"+str(optiG.param_groups[0]['lr']))\n",
    "    for x_,y_ in train_loader:\n",
    "        D.zero_grad()#将所有模型参数的梯度置为0，如果不进行会将梯度累计一起计算，等于是batch增大了，加大对GPU的负担\n",
    "        minibatch=x_.size()[0]#求出每个batchsize的大小\n",
    "        ##################训练判别器###############\n",
    "        ##-------------------------对真实样本经过判别器之后的LOSS-----------------------########\n",
    "        y_real_=torch.ones(minibatch,1)\n",
    "        y_label_=torch.zeros(minibatch,10)\n",
    "        y_label_.scatter_(1,y_.view(minibatch,1),1) #label的one-hot编码\n",
    "        #print(y_label_)\n",
    "        x_=x_.view(-1,28*28)  ##代表的是图片\n",
    "        ###将上面的变量放到GPU上去\n",
    "        y_real_, y_label_,x_=y_real_.to(device),y_label_.to(device),x_.to(device)\n",
    "        #计算判别器对于真实样本的损失\n",
    "        D_result=D(x_,y_label_)\n",
    "        D_real_loss=loss(D_result,y_real_)\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        ##-----------------------------对生成器生成的数据来求判别器的LOSS---------------###########\n",
    "        y_fake_=torch.zeros(minibatch,1)  #判别器用于判断的标签\n",
    "        z_=torch.rand(minibatch,100)#生成噪声\n",
    "        y_=(torch.rand(minibatch,1)*10).type(torch.LongTensor)#生成0-9的整数标签留给后面的scatter_使用\n",
    "        y_label_=torch.zeros(minibatch,10)\n",
    "        y_label_.scatter_(1,y_.view(minibatch,1),1)\n",
    "        #print(y_label_)\n",
    "        ####将上面的变量放到GPU上去\n",
    "        z_,y_label_,y_fake_=z_.to(device),y_label_.to(device),y_fake_.to(device)\n",
    "        ##生成器生成图像\n",
    "        G_result=G(z_,y_label_)\n",
    "        #计算判别器对于虚假样本的损失\n",
    "        D_result=D(G_result,y_label_)     \n",
    "        D_fake_loss=loss(D_result,y_fake_)    #降低损失，即让判别器把虚假样本判别成虚假的    \n",
    "        ##-------------------------------------------------------------------------#########\n",
    "        ###一起反向传播\n",
    "        D_train_loss=D_real_loss+D_fake_loss\n",
    "        D_train_loss.backward()\n",
    "        optiD.step()\n",
    "        D_losses.append(D_train_loss.item())   #判别器的损失get\n",
    "        ##########训练生成器\n",
    "        \n",
    "        G.zero_grad()\n",
    "        y_real_=torch.ones(minibatch,1)\n",
    "        z_=torch.rand(minibatch,100)#生成噪声\n",
    "        y_=(torch.rand(minibatch,1)*10).type(torch.LongTensor)#生成0-9的整数标签留给后面的scatter_使用\n",
    "        y_label_=torch.zeros(minibatch,10)\n",
    "        y_label_.scatter_(1,y_.view(minibatch,1),1)\n",
    "        #print(y_label_)\n",
    "        z_,y_label_,y_real_=z_.to(device),y_label_.to(device),y_real_.to(device)\n",
    "        G_result=G(z_,y_label_)\n",
    "        D_result=D(G_result,y_label_)\n",
    "        G_train_loss=loss(D_result,y_real_)    #降低损失，让判别器把虚假样本判成真样本\n",
    "        G_train_loss.backward()\n",
    "        optiG.step()\n",
    "        G_losses.append(G_train_loss.item())\n",
    "    #打印每一个epoch的生成器和判别器平均损失\n",
    "\n",
    "    print(\"第%d个epoch： G的损失:%.2f, D的损失:%.2f\" % (epoch,sum(G_losses)/len(G_losses),sum(D_losses)/len(D_losses)))\n",
    "    #保存效果图\n",
    "    pathName=\"./result/\"+str(epoch)+\".png\"\n",
    "    save_result(pathName)  \n",
    "    epoch_time=time.time()-epoch_start_time\n",
    "    print(\"此epoch耗时为：%.2f s\" %(epoch_time))\n",
    "end_time=time.time()\n",
    "dura = end_time-start_time              \n",
    "print(\"训练总耗时为：%.2f s\" %(dura))\n",
    "#保存网络模型\n",
    "torch.save(G.state_dict(),\"./G.pkl\")\n",
    "torch.save(D.state_dict(),\"./D.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把生成的图像给做成gif展示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "imgs=[]\n",
    "for i in range(train_epoch):\n",
    "        imgpath=\"./result/\"+str(i)+\".png\"\n",
    "        imgs.append(Image.open(imgpath))\n",
    "imgs[0].save(\"./result.gif\",save_all=True,append_images=imgs,duration=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-gpu] *",
   "language": "python",
   "name": "conda-env-pytorch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
